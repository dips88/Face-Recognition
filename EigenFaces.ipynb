{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2, os\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "recognizer = cv2.face.createEigenFaceRecognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_images_and_labels(path):\n",
    "    # Append all the absolute image paths in a list image_paths\n",
    "    # We will not read the image with the .sad extension in the training set\n",
    "    # Rather, we will use them to test our accuracy of the training\n",
    "    image_paths = [os.path.join(path, f) for f in os.listdir(path) if not f.endswith('.sad')]\n",
    "    # images will contains face images\n",
    "    images = []\n",
    "    # labels will contains the label that is assigned to the image\n",
    "    labels = []\n",
    "    for image_path in image_paths:\n",
    "        # Read the image and convert to grayscale\n",
    "        image_pil = Image.open(image_path).convert('L')\n",
    "        \n",
    "        # Convert the image format into numpy array\n",
    "        image = np.array(image_pil, 'uint8')\n",
    "        # Get the label of the image\n",
    "        nbr = int(os.path.split(image_path)[1].split(\".\")[0].replace(\"subject\", \"\"))\n",
    "        # Detect the face in the image\n",
    "        faces = faceCascade.detectMultiScale(image)\n",
    "        # If face is detected, append the face to images and the label to labels\n",
    "        for (x, y, w, h) in faces:\n",
    "            cropped = image[y: y + h, x: x + w]\n",
    "            cropped = cv2.resize(cropped,(154,154))\n",
    "            images.append(cropped)\n",
    "            labels.append(nbr)\n",
    "            \n",
    "    # return the images list and labels list\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Path to the Yale Dataset\n",
    "path = 'yalefaces' \n",
    "# The folder yalefaces is in the same folder as this python script\n",
    "# Call the get_images_and_labels function and get the face images and the \n",
    "# corresponding labels\n",
    "images, labels = get_images_and_labels(path)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Perform the training\n",
    "recognizer.train(images, np.array(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 is Correctly Recognized\n",
      "2 is Correctly Recognized\n",
      "3 is Correctly Recognized\n",
      "4 is Correctly Recognized\n",
      "5 is Correctly Recognized\n",
      "6 is Correctly Recognized\n",
      "7 is Correctly Recognized\n",
      "8 is Correctly Recognized\n",
      "9 is Correctly Recognized\n",
      "10 is Correctly Recognized\n",
      "11 is Correctly Recognized\n",
      "12 is Correctly Recognized\n",
      "13 is Correctly Recognized\n",
      "14 is Correctly Recognized\n",
      "15 is Correctly Recognized\n"
     ]
    }
   ],
   "source": [
    "# Append the images with the extension .sad into image_paths\n",
    "image_paths = [os.path.join(path, f) for f in os.listdir(path) if f.endswith('.sad')]\n",
    "for image_path in image_paths:\n",
    "    predict_image_pil = Image.open(image_path).convert('L')\n",
    "    predict_image = np.array(predict_image_pil, 'uint8')\n",
    "    faces = faceCascade.detectMultiScale(predict_image)\n",
    "    for (x, y, w, h) in faces:\n",
    "        cropped = predict_image[y: y + h, x: x + w].copy()\n",
    "        cropped = cv2.resize(cropped,(154,154))\n",
    "        nbr_predicted  = recognizer.predict(cropped)\n",
    "        nbr_actual = int(os.path.split(image_path)[1].split(\".\")[0].replace(\"subject\", \"\"))\n",
    "        if nbr_actual == nbr_predicted:\n",
    "            print (\"{} is Correctly Recognized\".format(nbr_actual))\n",
    "        else:\n",
    "            print (\"{} is Incorrectly Recognized as {}\".format(nbr_actual, nbr_predicted))\n",
    "        cv2.imshow(\"Recognizing Face\", predict_image[y: y + h, x: x + w])\n",
    "        cv2.waitKey(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
